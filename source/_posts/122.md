---
title: TensorFlow介绍
date: 2017-12-23 04:06:10
tags: TensorFlow
categories: TensorFlow
---

![img](https://pic3.zhimg.com/v2-46997b3e71ec525275ad88506d953016_b.jpg)

<!--more-->

TensorFlow 是世界上最受欢迎的开源机器学习框架，它具有快速、灵活并适合产品级大规模应用等特点，让每个开发者和研究者都能方便地使用人工智能来解决多样化的挑战。

今天给大家推荐的这个视频（及文字实录），是2017年谷歌开发者大会欧洲站上，谷歌研究院工程师Andrew Gasparovic所做演讲。他用深入浅出、妙趣横生的方式，给大家分享了TensorFlow的发展情况与最新成果。

大家好，我叫Andrew Gasparovic。我是来自谷歌欧洲研究部苏黎世的一名工程师，致力于研究机器智能的基础设施。

今天我很高兴可以给大家介绍如何使用TensorFlow进行机器学习。

首先我将向你们讲解TensorFlow，然后再给大家举一些例子，关于我们如何在Google使用TensorFlow。接着分享一些最新以及即将出现的发展情况。然后再谈谈如何使用机器学习解决实际问题。

**TensorFlow是什么?**

首先介绍下TensorFlow究竟是做什么的，以及人们为什么想要使用它。

**TensorFlow能够让你直接解决各种机器学习任务。**目标就是在一般情况下，无论你遇到什么问题，TensorFlow都可以在一定程度上提供API的支持。

总的来说TensorFlow就是为了快而设计的，所以它针对你实际使用的硬件和平台做了优化。

其中在机器学习框架方面，TensorFlow的真正独特之处在于，能够在5行或者10行代码中构建模型。然后应用这个模型，进行扩展做出产品。

因此，你能够在几十甚至几百个机器的簇上进行训练。从而用该模型进行非常低的延迟预测。

我们在这里稍微展开说一下什么是模型。以及机器学习是怎样与模型相关联的。

这里有个简单的预测问题，判断一张图片中包含的是猫还是狗。这用传统的编程方法很难甚至不可能解决。因为很难制定出一系列规则，来决定什么是猫什么是狗。最重要该如何把握所有的变量，比如品种、姿势、亮度、以及比例等等。

因此作为替代，我们可以构建一个神经网络。这像是人脑中神经元运行的极简版本。

图中每个小点都是一个神经元，这些神经元以层为集合单位被关联起来。从那些我们所看到的图片，到我们所能理解的输出。

接着浏览大量猫狗的图片，它们均被标注为正确的类别，然后进行预测。一开始，所有这些神经元都被随机地初始化，完全凭猜。

我们要计算猜测与正确结果之间的距离，即误差。然后使用误差，来调整神经元之间的连接强度。基本上，我们想缓慢地逼近正确答案。在我们重复上述步骤约一百万次之后，你就可以得到一个不错的猫狗预测模型。

但是你真正想实现的，其实是创建一个预测猫狗的网站。用户给了你一张图片，你需要告诉他们这当中包含了猫还是狗。在训练中习得的连接强度，能使你的模型推广。

因此如果给出一张图片，即使它从未见过这张图，并且图片也没有附上任何标签，模型也能预测出图片中是狗。这是根据从神经元的权值习得的，关于猫狗本质的对比。至少是根据它所看的图片。

而模型真正能学习到什么程度，是一个基于模型大小和复杂度的函数。直到最近我们才有相应的计算机性能和工具，可以用来实验巨大且复杂的模型。

这张图片是神经网络在5到10年前的样子，那时还只有为数不多的几个神经元。每层神经元完全相互连接，但也没有那么多层神经元。最后的结果也没有那么准确。

事实上对于类似计算机视觉的问题，过去的神经网络几乎无用武之地。相比于为某个确切的任务，由专家们专门手动调节的模型。

如今可以用来与图像分类的神经网络作比较，这个被称为Inception。它的设计思路是给出一张图片，它就能从成千上万，我记得是大约1万7千种类别中，预测出图中包含了什么。

借助于TensorFlow的框架，你能够训练出这样的模型。含许多层，并且比早期的神经网络更复杂。

**这就是我们说深度学习时所指的"深度”。**在这里'深度'指的就是，层与层之间更深层次的协调。以及随之产生的更加复杂的连接。最终的结果就是你的模型中，有百万级别甚至十亿级别数量的神经元。这就是为什么通过深度神经网络得到的结果。能够极大地优于，早期的手工构建并且手工调试的模型。

但是，TensorFlow能够在大型神经网络中表现地如此高效的原因是，它能把你写的代码转换成操作图。而真正运行的正是这种图。

顺便提一下，**在这些操作之间运行的数据叫做张量(Tensor)**。这也是名字的来源。

因为你的模型以图的形式展现出来，你可以推迟或者删除不必要的操作。甚至重用部分结果。你还可以很轻松地实现的一个过程叫做**反向传播**。如果你还记得的话，当我们基于所见的样本以及计算的误差，来更新模型中的连接强度。这整个过程就是反向传播。

因为模型表现为操作图而不是代码，因此你不需要为此写额外的代码。只需直接自动地计算以及应用这些迭代更新。模型表现为图的另一个好处就是，在你的代码中，你可以用一行声明就表明:"我想这部分图在这里运行,我想另一部分图分布式运行在不同的机器群上"。

你甚至可以说"我想要这部分注重数学的图在GPU上运行,与此同时,数据输入部分的代码在CPU上运行"。

TensorFlow一开始就可以在CPU和GPU上运行，它还可以在iOS 安卓、甚至Raspberry Pi设备上加载模型，以及做一些像预测或者分类的推理型任务。

因此在我们的数据中心内部，我们使用专门打造的硬件TPU(tensor processing unit)，来提供TensorFlow图。

所以实现在网络中先反向传播，然后再前向传播。每一层神经元之间的连接强度，基本上就是非常大的矩阵数学运算。这正是TPU常做的，并且算得又快又好。

第二版TPU硬件我们称之为云TPU，之后我会多谈谈这方面。

曾有一段时间，Python几乎是构建TensorFlow图的唯一选择。直到现在它也是一个不错的选择。Python非常简单，现成的样例代码非常多，几乎支持任何内容。

但是也有来自很多其他语言的支持。因为TensorFlow是开源的，长期以来在社区的支持下，越来越多的语言开始支持TensorFlow。所以，最终的情况是，如果你对TensorFlow感兴趣，你可以用自己喜欢的语言使用TensorFlow。

在此我想说一下，我的TensorFlow Serving团队的同事们。上个月刚刚发布了他们的1.0版本。这对他们来说是一个十分重大的里程碑。

因为TensorFlow Serving是非常高性能的基础设施。你能够在自己的服务器上加载模型，用于低延时的推断请求。在内部，我们已经把它应用于大约800个产品上 。但是我们想把它作为开源分布的一部分 。

因为这是在实际部署中很重要的一个方面 。当我们说TensorFlow可用于生产时 ，这才能把用来做研究所写的代码与实际生产用来解决问题相区分 。

还有一个项目是称为TensorBoard的工具 ，这是包中的可视化工具之一 。这张图展示的是针对某个任务模型，学到的手写体数字簇。

总体来说，把模型的运行过程进行可视化 ，并且尝试对模型预测的结果进行调试 。

一直以来都是一个机器学习的难点，是许多机器学习框架中的薄弱环节。因此正如TensorFlow Serving，这也正是我们想要加入的内容 。

因为你不可能将其投入生产 ，除非真正弄清机器学习模型中的运行原理 。以及明确是否模型预测的结果与预期不同 ，还有当中的原因 。

所以总体而言 ，生产前的准备工作是构建成功框架的关键之一 ，这也使它与众不同 。

**TensorFlow自发布以来 ，就成为了GitHub上排名第一的机器学习开源库 。**自从发布以来的其使用量是惊人的 。这张图表显示了它自发行以来，在GitHub上的Star数。上一次我看的时候超过了6万8千点。

另一个原因就是，我们很重视自己在开源社区中的地位。 对于我们来说，这从来就不是随意打出一些代码，或者随意从源代码存储库中取出一些 ，选择开源然后就完事了。

自从发布以来，开放源码和开源贡献者，一直是整个过程中的重要部分。如今 TensorFlow中有超过1千为外部贡献者。

其中一些外部贡献者的添加了很多新的特性，如我前面提到的其他语言，额外的硬件支持。甚至是TensorFlow运行的全新平台。

我们开源工作的另一个方面是 ，确保用户能够高效，并了解如何最好地使用TensorFlow。

为此我们已经回答了Stack Overflow上数千个问题，同时也认真地研究并解决了我们GitHub Issue页面上的问题。我们希望从你在下载框架到实际发布模型时，都有非常无缝的体验。

只是需要明确的是，我们经常在谷歌里中使用TensorFlow。这张图显示了随着时间的推移，我们模型的源代码控制树的目录数量。

橙色线是当我们内部发布TensorFlow，可供所有项目使用时的情况。可以看到在此之前，有一些人对机器学习的兴趣 。比如一些人是白色名单，或使用我们先进的框架 。然后在其发布之后就激增了。

如今，谷歌有6千多个产品使用了TensorFlow。

**事实上，几乎谷歌所有的主要产品都使用TensorFlow，并以某种形式进行机器学习。**这给了我们大量的反馈和机会来进行优化。通过简化API，或添加新的API使其更容易使用。还提供一些我提到过的生产工具。

**可以用TensorFlow做什么?**

让我展示一些TensorFlow的应用实例。因为有各种各样的问题，这很好的展示它作为框架具有的灵活性。

谷歌翻译曾经使用逐词翻译的模型，一句句的短语，其性能仅此而已。

当中具有上千条由语言学家输入编写的手调代码。即便如此，这是无法体会人类语言的中差别和差异。

右侧是将中文"**请问，洗手间在哪里?**"翻译为"**Where Will the restroom?**"的例子，有很大的改进空间。我们使用全新的基于深度神经网络的系统，代替了之前的系统系统。该系统称为神经网络机器翻译。这是在TensorFlow上运行的。

结果是在一些情况下，许多语言组合的翻译质量上有显著提高，达到了85%。

原因在于模型会从整个一系列单词的角度来考虑，输入序列和输出序列。结果是你得到了更自然的输出，更像人工翻译的成果。例如 此处"**excuse me, where is the toilet?**”，就是一个更好的翻译结果。

继续这个翻译的主题。我们在翻译App中加入**实时相机翻译(Word Lens)**。而且是在手机上运行的，能在飞行模式使用，这是非常惊人的。

因为在同样的模型中，这结合了计算机视觉和翻译。我们在TensorFlow中加入了特性，使这些成为可能。

如今你可以在一个服务器的集群，或一台机器上对模型进行训练。你通常会这样做，然后对取该模型，缩小尺寸。从而适应设备，同时保持高质量。

谷歌图片就是加入机器学习功能而大为提升的例子。在6个月时间里，该团队使用基于Inception的图象分类系统，在谷歌图片中实时使用。

思路就是你通过输入词在图片中进行搜索。比如输入"海滩" ，就会得到海滩的图片。搜索"雨伞" ，就得到雨伞的图片。或者甚至搜索一个抽象的词如”晴天”。而且之前不用在你的图片中添加这这些标签。

另一个使用深层神经网络处理更复杂图像任务的，是来自谷歌研究院的**Show and Tell**。输入图像，并输出文字说明。这也始于Inception模型，但它不只是对出现在图像中的对象进行分类。还会得出自然的描述 并把握图像中对象之间的关系。

为了做到这一点，模型在人工生成说明的例子上进行调整。从而它习得了关系的内容。

当中的副作用是，模型更擅长描述图像中比如颜色的细节。因为它发现在人类更喜欢这类描述。

因此谷歌研究院将整个模型开源。在博客上有关于这方面很深度的帖子，你可以按照文章链接自己试试。

另外谷歌研究眼在致力于使用计算机视觉，对糖尿病性视网膜病变的状况进行诊断。

一般来说是你去看眼科医生，通过拍这样的图像，分析糖尿病视网膜病变的早期迹象。这很重要，因为如果尽早发现疾病，能够更容易治疗。但发展中国家没有足够多的眼科医生，所以很难及时发现病变。

我们发表在《美国医学会期刊》上发表了文章，当中指出在诊断该症状时，计算机视觉能够达到等同、甚至略优于平均眼科医生的水平。这让我们很兴奋，因为如果让该模型得到普及，就能够帮助发现更多类似症状，在为时已晚之前。

研究小组的最后一个问题是，让深层神经网络学习。什么样的结构能够解决不同的问题?那么我们能做的就是，从表现不佳的机器学习模型开始学习，直到达到一个更准确的模型，而无需人工干预。

这个模型建立了解决问题的机器学习模型，这些问题被称为学习会学习。这是一个非常令人兴奋的领域，未来几年会在该领域做出很多成果。

在你认为TensorFlow是用于长期研究、或者大预算的大型应用程序时，我想给你看一个种黄瓜的日本农民。

照片后面他的儿子，使用建了黄瓜自动分类器，使用TensorFlow Arduino Controller以及Raspberry Pi。

他通过属于九个类别的七千根黄瓜样本训练模型。这之前每次黄瓜收获后，他母亲需要用10个小时进行这项分类工作。

他说"**我想把分类工作交给AI来做，这样我们可以把更多精力放在培育好的黄瓜上**"。在训练完模型后，他用传送带将其与控制器连接，并将许多摄像头连接到Raspberry Pi。当每条黄瓜沿着传送带传送时，它的影像会被摄像头捕捉，然后并被自动分类。我认为这是一个实际运用机器学习的出色例子。

**TensorFlow的最新进展**

我认为自从TensorFlow 1.0版本发布起，它就非常擅长解决这一系列类问题。从那以后又有很多新的发展。

现在让我介绍一下。首先它变得更容易使用。就像说过的，在解决给出的各种问题时，TensorFlow非常灵活。

但它使用起来并不是最简单的。它在底层用分布式执行引擎。这个设备实际上用于执行图像处理操作，并在处理器中实现对该任务的分配，这个是不变的。

我们在1.0版本后，加入了Layers API。其理念是你可以构建模型，而无需直接进行图形和操作。但你仍然需要建立网络结构和所有的层，而且这类工作需要手工完成。

然后我们添加了Estimators API，能够更先进地选模型 结合输入 并进行训练和评估。现在的1.3版本，我们添加了另一层，我们称之为Canned Estimators。只需一行代码就能够创建深层神经网络分类器。

使用Estimators API 你能够免费获取，如分布式训练、自动快照。并且能够运行混合硬件，比如CPU和GPU。

同时对性能的改进能够应用于你的模型，我们发布了用不同硬件组合处理不同的任务的基准。这是很重要的，因为这显示了随着时间的推移，我们将如何继续提高性能。但同样重要的是， 这说明了针对你的硬件组合，TensorFlow解决问题的性能。

至于不常见的配置，这个之前提到的云TPU。这是第二代TPU(Tensor Processing Unit)。

第一代我们只用于加快机器学习的推算部分，第二代还加速了训练部分，总的来说这是一个巨大的进步。因为每个云TPU能够每秒能计算180万亿次，但这意味着需要每次连接64个TUP pod。一个pod是每秒能计算11.5万亿次。这是很大的运算量。

之前提到的神经网络翻译模型，需要一整天进行训练，而且是用我们能找到的32个GPU。如今达到同样的正确率，使用1/8的TPU只需半天就可以完成训练。

在一年内我们将面向外部用户提供在云平台使用云TPU。之后我会分享这方面的信息。

还要确保我们能够充分利用用于处理机器学习任务的任何硬件，无论是TPU还是GPU，甚至只是你的CPU支持的指令等。

我们一直使用编译器，将之前提到的图直接转换为汇编码，称为加速线性代数(accelerated linear algebra)。

在TPU上运行时这必不可少，并且在Jet Mode下为CPU和GPU编写图。因此能够选择你硬件的对应内核。

还有第三适合手机端的模式。你能够事前编写模型，然后在移动设备上运行预测。优点是编写的模型要小得多，但仍然能够在特定设备上高效运行。

关于手机端，最后要注意的是我们推出了TensorFlow Lite。专门为安卓移动设备推出的全新runtime。原理是在移动应用程序中放入很薄的引擎，完全支持你设备上的硬件，省去了所有不必要的通用代码。

当你结合该编译模型时，你能够高效实用硬件，且内存占用小。

因此你能够进行之前提到的设备上的推断任务，或者新出的Federated Learning。当中你可以利用在云端训练的模型，与此同时在个人的设备中有自己的训练数据。这从未被发送到云，但是可以在设备上整合。

**如何开始学习TensorFlow**

即使你有很多编程经验，我还是会说**进入机器学习领域是很难的，非常难**。

使用TensorFlow的好处之一在于，你处理的内容最终能够实际生产出来。不管你是什么水平，我想提供一些开始起步的建议。

第一个建议是利用网站[http://tensorflow.org**](http://tensorflow.org/)。上面有入门部分，附有可以实际操作的介绍，以及一些机器学习的任务。默认需要一些Python的知识，但仅此而已。

一旦开始，你可以一步步跟着教程学习。达到构建卷积网络等内容，这很适合处理图像分类任务。而递归神经网络适合处理语言及翻译任务。

在 [http://playground.TensorFlow.org**](http://playground.tensorflow.org/) 上，有很有趣的不同神经网络架构和参数的演示。你可以试着改变层或神经元的数量，改变特征、学习率等。通过处理简单分类问题，了解神经网络的工作原理。

一旦你准备好开始真正构建用于生产的模型，我建议使用高等级的**Estimator，以及Canned Estimator API**。

因为你会自动地获得，比如保存和恢复checkpoint 导出TensorBoard，以及分布式训练，不需要额外操作。因此百分之八九十的情况下，Estimators和Canned Estimators是不错的选择。

当然通过使用Estimators，只要你愿意，你也可以把模型移动到云TPU，几乎是自动的。

在[http://g.co/tpusignup**](http://g.co/tpusignup) 有一个申请表，如果你想了解更多信息的话。在这些链接中也可以了解更多关于TensorFlow Research Cloud的信息。

面向机器学习研究者，我们免费提供了上千个云TPU。因为有许多人有好的想法，但缺乏合适硬件进行先进研究。如果你想申请的话，可以看看这些链接。

最后还有一些优秀的机器学习在线课程，比如Google Developers的YouTube频道。Udacity还有使用TensorFlow的深度学习课程。深入机器学习的理论和数学背景。如果你喜欢那个课程，并且想继续的话，获得它的机器学习纳米学位是不错的选择。

我真的希望你想继续深入机器学习，因为这是一个令人兴奋的领域，这比以往更容易，而且有很多的成果。

本文数据侠Andrew Gasparovic，任职于谷歌欧洲研究院机器智能部门。飞行员，跑步者，bloopmusic的开发者。

