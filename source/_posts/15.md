---
title: 15|零基础四周实现爬虫
date: 2018-02-06 13:11:25
tags: 爬虫
categories: 程序
---

##### 开始之前

[Python 爬虫的工具列表 附Github代码下载链接][https://segmentfault.com/a/1190000012769767#articleHeader4]

附一张Pycharm的破解方案

{% asset_img  1.jpg %}

<!--more-->

##### 第一周课程

###### [认识网页的构成][https://www.w3cschool.cn/dml2f0/a3wz1s15.html]

HTML是网络的通用语言,一种简单、通用的全置标记语言。HTML允许网页建设者建立文本与图片相结合的复杂页面，无论使用的是什么类型的电脑或浏览器，这些页面可以被网上任何所人浏览到。比如，你现在看到的就是这种语言写的页面。 

最简单的HTML代码

```html
<!DOCTYPE html> 
＜html＞
＜head＞
<meta http-equiv="Content-Type" content="text/html; charset=gb2312" />
＜title＞标题＜title＞
<meta name="keywords" content="关键字" /> 
<meta name="description" content="本页描述或关键字描述" /> 
＜/head＞
＜body＞
..........内容..........
＜/body＞
<footer>
</footer>
＜/html＞
```

   **HTML为结构，CSS为样式，JS为功能**

###### 读取本地文件并解析文件数据

```python
from bs4 import BeautifulSoup
path = './1_2_homework_required/index.html' 
#这里使用了相对路径,只要你本地有这个文件就能打开

with open(path, 'r') as wb_data: # 使用with open打开本地文件
    soup = BeautifulSoup(wb_data, 'lxml') # 解析网页内容
    # print(wb_data)

    titles = Soup.select('body > div > div > div.col-md-9 > div > div > div > div.caption > h4 > a') # 复制每个元素的css selector 路径即可
    images = Soup.select('body > div > div > div.col-md-9 > div > div > div > img')
    reviews = Soup.select('body > div > div > div.col-md-9 > div > div > div > div.ratings > p.pull-right')
    prices = Soup.select('body > div > div > div.col-md-9 > div > div > div > div.caption > h4.pull-right')
    stars = Soup.select('body > div > div > div.col-md-9 > div > div > div > div.ratings > p:nth-of-type(2)')
    # 为了从父节点开始取,此处保留:nth-of-type(2),观察网页,多取几个星星的selector,就发现规律了

# print(titles,images,rates,prices,stars,sep='\n--------\n')  # 打印每个元素,其中sep='\n--------\n'是为了在不同元素之间添加分割线

for title, image, review, price, star in zip(titles, images, reviews, prices, stars):  # 使用for循环,把每个元素装到字典中
    data = {
        'title': title.get_text(), # 使用get_text()方法取出文本
        'image': image.get('src'), # 使用get 方法取出带有src的图片链接
        'review': review.get_text(),
        'price': price.get_text(),
        'star': len(star.find_all("span", class_='glyphicon glyphicon-star'))
        # 观察发现,每一个星星会有一次<span class="glyphicon glyphicon-star"></span>,所以我们统计有多少次,就知道有多少个星星了;
        # 使用find_all 统计有几处是★的样式,第一个参数定位标签名,第二个参数定位css 样式,具体可以参考BeautifulSoup 文档示例http://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/#find-all;
        # 由于find_all()返回的结果是列表,我们再使用len()方法去计算列表中的元素个数,也就是星星的数量
    }
    print(data)

```

###### 读取网页文件并解析

```python
from bs4 import BeautifulSoup
import requests
import time

url_saves = 'http://www.tripadvisor.com/Saves#37685322'
url = 'https://cn.tripadvisor.com/Attractions-g60763-Activities-New_York_City_New_York.html'
urls = ['https://cn.tripadvisor.com/Attractions-g60763-Activities-oa{}-New_York_City_New_York.html#ATTRACTION_LIST'.format(str(i)) for i in range(30,930,30)]

headers = {
    'User-Agent':'',
    'Cookie':''
}


def get_attractions(url,data=None):
    wb_data = requests.get(url)
    time.sleep(4)
    soup = BeautifulSoup(wb_data.text,'lxml')
    titles    = soup.select('div.property_title > a[target="_blank"]')
    imgs      = soup.select('img[width="160"]')
    cates     = soup.select('div.p13n_reasoning_v2')

    if data == None:
        for title,img,cate in zip(titles,imgs,cates):
            data = {
                'title'  :title.get_text(),
                'img'    :img.get('src'),
                'cate'   :list(cate.stripped_strings),
                }
        print(data)


def get_favs(url,data=None):
    wb_data = requests.get(url,headers=headers)
    soup      = BeautifulSoup(wb_data.text,'lxml')
    titles    = soup.select('a.location-name')
    imgs      = soup.select('div.photo > div.sizedThumb > img.photo_image')
    metas = soup.select('span.format_address')

    if data == None:
        for title,img,meta in zip(titles,imgs,metas):
            data = {
                'title'  :title.get_text(),
                'img'    :img.get('src'),
                'meta'   :list(meta.stripped_strings)
            }
            print(data)

for single_url in urls:
    get_attractions(single_url)


# from mobile web site
'''
headers = {
    'User-Agent':'', #mobile device user agent from chrome
}


mb_data = requests.get(url,headers=headers)
soup = BeautifulSoup(mb_data.text,'lxml')
imgs = soup.select('div.thumb.thumbLLR.soThumb > img')
for i in imgs:
    print(i.get('src'))
'''

```

