---
title: sklearn Kmeans算法
date: 2017-12-19 23:52:29
tags: sklearn
categories: sklearn
---

##### 算法介绍

k-means算法以k为参数，把n个对象分成k个簇，使簇内具有较高的相似度，而簇间的相似度较低。
其处理过程如下：
​	1.随机选择k个点作为初始的聚类中心；
​	2.对于剩下的点，根据其与聚类中心的距离，将其归入最近的簇
​	3.对每个簇，计算所有点的均值作为新的聚类中心
​	4.重复2、 3直到聚类中心不再发生改变 

##### 数据集：31省市居民家庭消费水平-city.txt

**数据介绍：**
现有1999年全国31个省份城镇居民家庭平均每人全年消费性支出的八个主要变量数据，这八个变量分别是：食品、 衣着、 家庭设备用品及服务、 医疗保健、 交通和通讯、 娱乐教育文化服务、 居住以及杂项商品和服务。 利用已有数据，对31个省份进行聚类。
**实验目的：**
通过聚类，了解1999年各个省份的消费水平在国内的情况。 

<!--more-->

```python
北京,2959.19,730.79,749.41,513.34,467.87,1141.82,478.42,457.64
天津,2459.77,495.47,697.33,302.87,284.19,735.97,570.84,305.08
河北,1495.63,515.90,362.37,285.32,272.95,540.58,364.91,188.63
山西,1406.33,477.77,290.15,208.57,201.50,414.72,281.84,212.10
内蒙古,1303.97,524.29,254.83,192.17,249.81,463.09,287.87,192.96
辽宁,1730.84,553.90,246.91,279.81,239.18,445.20,330.24,163.86
吉林,1561.86,492.42,200.49,218.36,220.69,459.62,360.48,147.76
黑龙江,1410.11,510.71,211.88,277.11,224.65,376.82,317.61,152.85
上海,3712.31,550.74,893.37,346.93,527.00,1034.98,720.33,462.03
江苏,2207.58,449.37,572.40,211.92,302.09,585.23,429.77,252.54
浙江,2629.16,557.32,689.73,435.69,514.66,795.87,575.76,323.36
安徽,1844.78,430.29,271.28,126.33,250.56,513.18,314.00,151.39
福建,2709.46,428.11,334.12,160.77,405.14,461.67,535.13,232.29
江西,1563.78,303.65,233.81,107.90,209.70,393.99,509.39,160.12
山东,1675.75,613.32,550.71,219.79,272.59,599.43,371.62,211.84
河南,1427.65,431.79,288.55,208.14,217.00,337.76,421.31,165.32
湖南,1942.23,512.27,401.39,206.06,321.29,697.22,492.60,226.45
湖北,1783.43,511.88,282.84,201.01,237.60,617.74,523.52,182.52
广东,3055.17,353.23,564.56,356.27,811.88,873.06,1082.82,420.81
广西,2033.87,300.82,338.65,157.78,329.06,621.74,587.02,218.27
海南,2057.86,186.44,202.72,171.79,329.65,477.17,312.93,279.19
重庆,2303.29,589.99,516.21,236.55,403.92,730.05,438.41,225.80
四川,1974.28,507.76,344.79,203.21,240.24,575.10,430.36,223.46
贵州,1673.82,437.75,461.61,153.32,254.66,445.59,346.11,191.48
云南,2194.25,537.01,369.07,249.54,290.84,561.91,407.70,330.95
西藏,2646.61,839.70,204.44,209.11,379.30,371.04,269.59,389.33
陕西,1472.95,390.89,447.95,259.51,230.61,490.90,469.10,191.34
甘肃,1525.57,472.98,328.90,219.86,206.65,449.69,249.66,228.19
青海,1654.69,437.77,258.78,303.00,244.93,479.53,288.56,236.51
宁夏,1375.46,480.89,273.84,317.32,251.08,424.75,228.73,195.93
新疆,1608.82,536.05,432.46,235.82,250.28,541.30,344.85,214.40
```

#####  代码


```python
# -*- coding: utf-8 -*-
"""
Created on Thu Dec 21 12:19:16 2017

@author: Administrator
"""
import numpy as np
from sklearn.cluster import KMeans

def loadData(filePath): 
    file = open(filePath, 'r+')
    lines = file.readlines()  #读取文件中所有数据，适合内存足够大
    
    retData = []
    retCityName = []
    for line in lines:
        items = line.split(",")  #划分
        retCityName.append(items[0])
        retData.append([float(items[i]) for i in range(1,len(items))]) #二维数组的追加
    return retData,retCityName

if __name__ == '__main__':    #定义主方法
    filePath = "C:\\Users\\Administrator\\Desktop\\31省市居民家庭消费水平-city.txt"
    retData,retCityName = loadData(filePath)
    km = KMeans(n_clusters = 3)  #设置聚类中心
    km.fit(retData)   #数据聚类
    label = km.labels_  #聚类后的标签划分
    centroids = km.cluster_centers_  #聚类后的中心
    expenses = np.sum(centroids,axis =1)  #对每一个聚类中心求和       
    print(expenses)  #输出三类城市各自的消费水平
    CityCluster = [[],[],[]]
    for i in range(len(retCityName)):
       CityCluster[label[i]].append(retCityName[i])  #标签按照聚类中心划分
    print(CityCluster)
```

#####   输出结果

从结果可以看出消费水平相近的省市聚集在了一类，例如消费最高的“ 北京”“ 上海”“ 广东”聚集在了消费最高的类别。 

```python
[ 7754.65666667  5113.54        3827.86588235]
[['北京', '上海', '广东'], ['天津', '江苏', '浙江', '福建', '湖南', '广西', '海南', '重庆', '四川', '云南', '西藏'], ['河北', '山西', '内蒙古', '辽宁', '吉林', '黑龙江', '安徽', '江西', '山东', '河南', '湖北', '贵州', '陕西', '甘肃', '青海', '宁夏', '新疆']]
```

##### 算法分析

 k-means算法比较简单，但也有几个比较大的缺点：

（1）k值的选择是用户指定的，不同的k得到的结果会有挺大的不同

（2）对k个初始质心的选择比较敏感，容易陷入局部最小值。

（3）数据库比较大的时候，收敛会比较慢。

k-means老早就出现在江湖了。所以以上的这些不足也被世人的目光敏锐的捕捉到，并融入世人的智慧进行了某种程度上的改良。例如问题（1）对k的选择可以先用一些算法分析数据的分布，如重心和密度等，然后选择合适的k。而对问题（2），有人提出了另一个成为二分k均值（bisecting k-means）算法，它对初始的k个质心的选择就不太敏感。

##### 补充

计算两条数据相似性时，Sklearn 的K-Means默认用的是欧式距离。 虽然还有余弦相似度，马氏距离等多种方法，但没有设定计算距离方法的参数。如果想要自定义计算距离的方式时， 建 议 使 用 `scipy.spatial.distance.cdist` 方法。 使用形式：`scipy.spatial.distance.cdist(A, B, metric=‘cosine’ )` 



